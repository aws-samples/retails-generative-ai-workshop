{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dda2e72",
   "metadata": {},
   "source": [
    "<h1> Similarity Search - Embeddings </h1>\n",
    "<br>\n",
    "\n",
    "Before starting, please make sure this notebook is using **conda_python3** kernel from the top right!\n",
    "\n",
    "Run all the cells and inspect the output of each cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8eab34",
   "metadata": {},
   "source": [
    "### What are embeddings?\n",
    "\n",
    "Embedding refers to the process of transforming objects such as text, images, video, or audio into numerical representations that reside in a high-dimensional vector space. In short, embeddings represent items like words as vectors of numbers. After generating these embeddings, an application can perform similarity searches within the vector space. Words with similar meanings will have similar vectors.\n",
    "\n",
    "The following diagram provides a visual representation of what this looks like for word embeddings i.e., words that are semantically similar are close together in the embedding space. \n",
    "\n",
    "![Vector](../images/vector.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233f7586",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "In this notebook, you will create a **Similarity Search** application using Amazon Titan Embeddings model and Amazon RDS. We use vector embeddings to retrieve similar products in the catalog based on our search keyword. \n",
    "\n",
    "\n",
    "* You will search products in the catalog using a search keyword. Example: red dress for a wedding.\n",
    "* The search keyword will be converted into vector embeddings at runtime using Titan Embeddings  model.\n",
    "* These search embeddings will be queried against the Product embeddings we stored in the RDS database using pgvector extension. This query will retrieve products similar to the search keyword.\n",
    "* The similarity search results will be displayed.\n",
    "\n",
    "![Vector Search](../images/vector-search.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f635e8e2",
   "metadata": {},
   "source": [
    "### Install required dependencies\n",
    "\n",
    "**Important:** You may see an ERROR or a warning that \"you may need to restart the kernel\" from the following cell. **Ignore** and proceed with the next cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fd2fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --quiet --no-build-isolation --upgrade \\\n",
    "    \"boto3==1.28.63\" \\\n",
    "    \"awscli==1.29.63\" \\\n",
    "    \"botocore==1.31.63\" \\\n",
    "    \"langchain==0.0.309\" \\\n",
    "    \"psycopg2-binary==2.9.9\" \\\n",
    "    \"pgvector==0.2.3\" \\\n",
    "    \"numpy==1.26.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa45f10",
   "metadata": {},
   "source": [
    "<h3> Import required packages </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6afab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "import botocore\n",
    "from langchain import PromptTemplate\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "\n",
    "# For vector search\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "import psycopg2\n",
    "from pgvector.psycopg2 import register_vector\n",
    "import numpy as np\n",
    "\n",
    "# For image operations\n",
    "from PIL import Image\n",
    "import base64\n",
    "import io\n",
    "import requests\n",
    "\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "from utils import bedrock, print_ww"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e50c88a",
   "metadata": {},
   "source": [
    "<h3> Initialize Bedrock client </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa0fbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3_bedrock = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78992b7d",
   "metadata": {},
   "source": [
    "#### Initialize Amazon Bedrock Embeddings model \n",
    "\n",
    "We are using Titan Embeddings model to convert our search keyword to vector embeddings to perform similarity search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3a0950",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelId = \"amazon.titan-embed-text-v1\"\n",
    "bedrock_embeddings = BedrockEmbeddings(model_id=modelId, client=boto3_bedrock)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549adaab",
   "metadata": {},
   "source": [
    "#### Define a search keyword and create vector embedding for that keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ca0142",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = \"floral prints\"\n",
    "print(keyword)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6ddf8d",
   "metadata": {},
   "source": [
    "#### Now let's create vector embedding for this keyword using Bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9842df64",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_embedding = list(bedrock_embeddings.embed_query(keyword))\n",
    "print(search_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3790e52",
   "metadata": {},
   "source": [
    "We are going to use the search embeddings to query the RDS vector knowledge base. This vector database is already prepopulated with embeddings for all the products in [this](https://github.com/zalandoresearch/feidegger/blob/master/data/FEIDEGGER_release_1.2.json) catalog. We used the same [FEIDEGGER](https://github.com/zalandoresearch/feidegger/tree/master) dataset to generate all the vector embeddings. \n",
    "\n",
    "Please note that in order to save time, embeddings for all the 8732 products in this dataset have been **pre-populated** into your Amazon RDS database. The process to create vector embeddings for these many embeddings takes about ~20-30 minutes. In order to store and query these embeddings, your RDS database needs to have [pgvector](https://github.com/pgvector/pgvector) extension installed. It has also been pre-installed in your RDS instance.\n",
    "\n",
    "This is the [notebook](https://github.com/aws-samples/retails-generative-ai-workshop/blob/ai/notebooks/create_embeddings_with_titan.ipynb) that shows how we pre-populated the embeddings. This is **just for your reference**. We recommend reviewing this code and other documentations **after the workshop**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde0ff4b",
   "metadata": {},
   "source": [
    "#### Now lets connect to Amazon RDS and query the pre-populated embeddings based on the search keyword "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6ab769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize secrets manager\n",
    "secrets = boto3.client('secretsmanager')\n",
    "\n",
    "sm_response = secrets.get_secret_value(SecretId='postgresdb-secrets')\n",
    "\n",
    "database_secrets = json.loads(sm_response['SecretString'])\n",
    "\n",
    "dbhost = database_secrets['host']\n",
    "dbport = database_secrets['port']\n",
    "dbuser = database_secrets['username']\n",
    "dbpass = database_secrets['password']\n",
    "dbname = database_secrets['vectorDbIdentifier']\n",
    "\n",
    "# Connect to the RDS vectordb database \n",
    "dbconn = psycopg2.connect(host=dbhost, user=dbuser, password=dbpass, port=dbport, database=dbname, connect_timeout=10)\n",
    "dbconn.set_session(autocommit=True)\n",
    "register_vector(dbconn)\n",
    "cur = dbconn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a228fb",
   "metadata": {},
   "source": [
    "#### Execute search query \n",
    "\n",
    "Here, we perform similarity search by querying the search keyword embedding against the pre-populated product embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd9cb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limiting search result to 2 for now\n",
    "cur.execute(\"\"\"SELECT id, url, description, descriptions_embeddings \n",
    "                        FROM vector_products\n",
    "                        ORDER BY descriptions_embeddings <-> %s limit 2;\"\"\", \n",
    "                        (np.array(search_embedding),))\n",
    "\n",
    "# Fetch search result\n",
    "dbresult = cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f94ce24",
   "metadata": {},
   "source": [
    "#### Display similarity search result\n",
    "\n",
    "This search result contains top 2 products that are similar to our search keyword. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa92746",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in dbresult:\n",
    "    # Get similar product IDs\n",
    "    product_item_id = x[0]\n",
    "    \n",
    "    # Get similar product descriptions\n",
    "    desc = x[2]\n",
    "    \n",
    "    # Get image from URL\n",
    "    url = x[1].split('?')[0]\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(io.BytesIO(response.content))\n",
    "    img = img.resize((256, 256))\n",
    "    \n",
    "    # Print similarity search results\n",
    "    print(\"Product ID: \" +str(product_item_id))\n",
    "    print(\"\\n\"+desc)\n",
    "    img.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e368b60",
   "metadata": {},
   "source": [
    "### You've successfully created a similarity search application using Amazon Bedrock Embeddings!\n",
    "\n",
    "#### Now, let's integrate this feature into our retail web application. Please go back to Workshop Studio and follow the instructions to build this feature using your Cloud9 IDE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6218dd1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
