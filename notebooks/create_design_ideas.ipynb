{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cd1a04e",
   "metadata": {},
   "source": [
    "<h1> Create New Design Ideas - Image Generation </h1>\n",
    "<br>\n",
    "\n",
    "Before starting, please make sure this notebook is using **conda_python3** kernel from the top right!\n",
    "\n",
    "Run all the cells and inspect the output of each cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181e96a5",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "In this notebook, you will generate new design idea based on the existing product image from the catalog. For this feature, we will invoke the Bedrock API directly without Langchain using Bedrock's [InvokeModel](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-runtime/client/invoke_model.html) API. \n",
    "\n",
    "We will use Stability AI's [Stable Diffusion](https://aws.amazon.com/bedrock/stable-diffusion/) model from Bedrock that supports Text-To-Image and Image-To-Image transformations. We pass two optional prompt inputs to the model.\n",
    "\n",
    "1. **Image prompt** will be used for creating new ideas from the existing image. For example: \"*add animal prints to the shirt*\". \n",
    "2. **Negative prompt** removes objects or styles in a way that may not be possible with image prompt alone. For example: \"*bad quality*\" or \"*poorly rendered*\". Stable diffusion model understands this prompt better than asking directly in the image prompt \"*do not generate poorly rendered image*\". \n",
    "\n",
    "![Image Generation](../images/image-generation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5e326a",
   "metadata": {},
   "source": [
    "### Install required dependencies\n",
    "\n",
    "**Important:** You may see an error or a warning that \"you may need to restart the kernel\" from the following cell. **Ignore** and proceed with the next cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f86df36",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --quiet --no-build-isolation --upgrade \\\n",
    "    \"boto3==1.28.63\" \\\n",
    "    \"awscli==1.29.63\" \\\n",
    "    \"botocore==1.31.63\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bbc91b",
   "metadata": {},
   "source": [
    "<h3> Import required packages </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1efe7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "# For image operations\n",
    "from PIL import Image\n",
    "import base64\n",
    "import io\n",
    "import requests\n",
    "\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "from utils import bedrock, print_ww"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775e1190",
   "metadata": {},
   "source": [
    "<h3> Initialize Bedrock client </h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80f14e4",
   "metadata": {},
   "outputs": [],
   "source": [
    " boto3_bedrock = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619d8c44",
   "metadata": {},
   "source": [
    "<p>Create a function to convert an image into a base64 string since Stabile Diffusion Model expects the image to be in base64 string format</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7654ed46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_base64(img) -> str:\n",
    "    if isinstance(img, str):\n",
    "        if os.path.isfile(img):\n",
    "            with open(img, \"rb\") as f:\n",
    "                return base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"File {img} does not exist\")\n",
    "    elif isinstance(img, Image.Image):\n",
    "        buffer = io.BytesIO()\n",
    "        img.save(buffer, format=\"PNG\")\n",
    "        return base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "    else:\n",
    "        raise ValueError(f\"Expected str (filename) or PIL Image. Got {type(img)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebd501a",
   "metadata": {},
   "source": [
    "### Read a sample product image\n",
    "\n",
    "**Note:** We are using one of the images from the <a href=\"https://github.com/zalandoresearch/feidegger/tree/master\">FEIDEGGER</a> dataset as an example. In the actual retail website, you will use the product image from the catalog. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895df4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = \"https://img01.ztat.net/article/spp-media-p1/3c8812d8b6233a55a5da06b19d780302/dc58460c157b426b817f13e7a2f087c5.jpg\"\n",
    "\n",
    "response = requests.get(image_url)\n",
    "image = Image.open(io.BytesIO(response.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ad540f",
   "metadata": {},
   "source": [
    "#### Resize product image to 512x512 and convert to base64 string format to comply with the requirements for Stable Diffusion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f1842f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = image.resize((512,512))\n",
    "resize.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93e3ae9",
   "metadata": {},
   "source": [
    "<h4> Convert this image to a base 64 string to pass into the model </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638c4d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_image_b64 = image_to_base64(resize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa962455",
   "metadata": {},
   "source": [
    "### Input prompts \n",
    "\n",
    "These are the image prompts and the negative prompts we will be passing to the Stable Diffusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a1c7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This prompt is used to generate new ideas from the existing image\n",
    "change_prompt = \"add floral prints to dress\"\n",
    "\n",
    "# Negative prompts that will be given -1.0 weight while generating new image\n",
    "negative_prompts = ['poorly rendered',\n",
    "                    'low quality',\n",
    "                    'disfigured',\n",
    "                    'disproportional']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9aeb3f",
   "metadata": {},
   "source": [
    "### Compose request to pass to Stable Diffusion Model\n",
    "\n",
    "This request includes our input prompts (image prompt, negative prompt) as well as the Stable Diffusion's [inference parameters](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-diffusion.html). **Note:** We describe these inference parameters in the **Explore** section of the workshop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c8cd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_request = json.dumps({\n",
    "                    \"text_prompts\": (\n",
    "                        [{\"text\": change_prompt, \"weight\": 1.0}]\n",
    "                        + [{\"text\": negprompt, \"weight\": -1.0} for negprompt in negative_prompts]\n",
    "                    ),\n",
    "                    \"cfg_scale\": 10,\n",
    "                    \"init_image\": init_image_b64,\n",
    "                    \"seed\": 0,\n",
    "                    \"start_schedule\": 0.5,\n",
    "                    \"steps\": 30,\n",
    "                    \"style_preset\": \"photographic\",\n",
    "                    \"image_strength\":0.5,\n",
    "                    \"denoising_strength\": 0.5\n",
    "                })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaefe11",
   "metadata": {},
   "source": [
    "### Call Bedrock to generate new image\n",
    "\n",
    "Notice that we directly use the InvokeModel API from Bedrock. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9615af",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = boto3_bedrock.invoke_model(body=sd_request, modelId=\"stability.stable-diffusion-xl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65879a6",
   "metadata": {},
   "source": [
    "### Render the newly generated image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae68c393",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_body = json.loads(response.get('body').read())\n",
    "genimage_b64_str = response_body[\"artifacts\"][0].get(\"base64\")\n",
    "genimage = Image.open(io.BytesIO(base64.decodebytes(bytes(genimage_b64_str, \"utf-8\"))))\n",
    "genimage.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9aa1d2",
   "metadata": {},
   "source": [
    "<h3> You've successfully created new design ideas for a product with Amazon Bedrock!</h3>\n",
    "\n",
    "Please stop the notebook kernel by selecting **Kernel -> Interrupt**.\n",
    "\n",
    "#### Now, let's integrate this feature into our retail web application. Please go back to Workshop Studio and follow the instructions to build this feature using your Cloud9 IDE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de68cf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
